{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project, Part 1-2:\n",
    "\n",
    "\n",
    "#### Problem statement\n",
    "\n",
    "millions of transactions payments to sellers are made everyday on ecommerce platform like shopee or lazada. with the increase in volume, an intelligent system of fraud detection is required for the employees to deal with the mounting transactions volume.\n",
    "\n",
    "Questions: \n",
    "Q1: how to  predict if a tranction is a fraud,using a selected list of given attributed\n",
    "Q2: is the classification model better than the current Flagging system that flagged transactions that are more than 200,000?\n",
    "\n",
    "So far 18 out of 18 flagged transactions are indeed Fraud\n",
    "but 8200 fraud transactions are NOT flagged.\n",
    "\n",
    "Attribute CO\n",
    "Target Columns: 'isFraud'\n",
    "\n",
    "Objective:\n",
    "Build a Classification Model that can predict if a transaction is fraud or not fraud\n",
    "    - model 1: Classification model using Linear Regression\n",
    "    - model 2: Logistic Regression\n",
    "    - model 3: decision tree?\n",
    "    \n",
    "Determine if the Classification model is more accurate compared to the baseline:\n",
    "    - the baseline is the current flagging system, which detected correctly 18 out of 8218 cases of actual fraud\n",
    "\n",
    "#### Data Source\n",
    "\n",
    "https://www.kaggle.com/ntnu-testimon/paysim1\n",
    "\n",
    "#### Risks or limitations\n",
    "- Curse of dimentionality:\n",
    "The dataset might be too thin 6m rows and\n",
    "- imbalance dataset, the non-fraud observations might be over presented\n",
    "- unknown variables that are not given in the orginal dataset that might have predicting power over whether a transaction is fraud\n",
    "\n",
    "### Description of Given Dataset\n",
    "\n",
    "1. step: Maps a unit of time in the real world. In this case 1 step is 1 hour of time.\n",
    "2. type: CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER\n",
    "3. amount: amount of the transaction in local currency\n",
    "4. nameOrig: customer who started the transaction\n",
    "5. oldbalanceOrg: initial balance before the transaction\n",
    "6. newbalanceOrig: customer's balance after the transaction.\n",
    "7. nameDest: recipient ID of the transaction. \n",
    "8. oldbalanceDest: initial recipient balance before the transaction.\n",
    "9. newbalanceDest: recipient's balance after the transaction.\n",
    "10. isFraud: identifies a fraudulent transaction (1) and non fraudulent (0)\n",
    "11. ifFlaggedFraud: flags illegal attempts to transfer more than 200.000 in a single transaction. \n",
    "\n",
    "\n",
    "#### Detailed Steps Taken:\n",
    "1. from sklearn.preprocessing import StandardScaler\n",
    "2. from sklearn.preprocessing import LabelEncoder\n",
    "3. smote\n",
    "3. train, test, split\n",
    "4. .fit\n",
    "\n",
    "5. sklearn.metrics import classification_report\n",
    "    - the row with the lower support col is the minority class\n",
    "    - Recal(sensitity) is the ratio of correctly predicted positive to th all observation \n",
    "7. calculate the Recall of the minority class, should definitely zoom in when do the classification report\n",
    "8. might need to sacrifice some precision for recall, because the cost of not detecting a fraud case is very high\n",
    "\n",
    "9. can adjust threshold in logistic regression (0.5 to 0.3) to adjust for the cost: if the cost of true positive is higher than false positive (adjust threhold is not frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type   amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT  9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT  1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER   181.00  C1305486145          181.0            0.00   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_file = 'C:\\\\Users\\\\harriet.ly\\\\Documents\\\\General Assembly Notes\\\\GA_Projects\\\\Projects\\\\Project 4\\\\fraud.csv'\n",
    "dataset = pd.read_csv(path_to_file)\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of rows and columns\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if there is any null values\n",
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6353307"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Check if there are repeated nameOrig and nameDest, if there are alot, we will use label encode them to use in our model, \n",
    "# otherwise, we drop them\n",
    "dataset['nameOrig'].nunique() # check if there are nameOrig with multiple transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2722362"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['nameDest'].nunique() # check if there are repeated nameDest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a lot fewer unique values for nameDest, meaning lots of repeated nameDest, hence we will proceed to encode nameDest \n",
    "# to use as an attribute in our model, and drop 'nameOrig' as it is considered as unique as an ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder on nameOrig and nameDest, these two variables are like IDs of the transactions but we will labelencode them to\n",
    "# include them into the model because they may contain\n",
    "# important information on the pattern/frequence of the same nameDest or nameOrg. \n",
    "# for isntance, highly repeated nameDest is an indicator of fraud\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#instantiate\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#Labelencode, this process might take a while to run\n",
    "le.fit(dataset['nameDest'])\n",
    "\n",
    "#nameOrigin_Encoded=le.transform(dataset['nameOrig'])\n",
    "nameDest_Encoded=le.transform(dataset['nameDest'])\n",
    "\n",
    "#dataset['nameOrigin_Encoded']=nameOrigin_Encoded\n",
    "dataset['nameDest_Encoded']=nameDest_Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head().sort_values(by='nameDest_Encoded',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Check if col isFlaggedFraud is completed relatd to Col amount. If amount > 200k, isFlaggedFraud =1\n",
    "data_flaggedFraud = dataset[dataset['isFlaggedFraud']==1]\n",
    "data_flaggedFraud[data_flaggedFraud['amount']<200000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Next, we check if the Col amount is equal to the abs(newbalanceOrig-oldbalanceOrg), In a genuine transaction, the difference between the\n",
    "# beginning and ending balance of the original account should be the same as the amount of transactions.\n",
    "# Note that oldbalanceOrg is not necessary always larger than newbalanceOrig, depending on what kind of transactions, hence we use abs()\n",
    "dataset['error_balanceOrig']= abs(dataset['oldbalanceOrg'] - dataset['newbalanceOrig'])-dataset['amount']\n",
    "dataset[dataset['error_balanceOrig']>0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 1m transactions whose amount do not tally with the origin beginning and ending balances, hence \n",
    "# we will include  'error_old_new_balanceOrigin' as an attribute in our fraud detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Next, we check if the Col amount is equal to the abs(newbalanceDest-oldbalanceDest)\n",
    "dataset['error_balanceDest']= abs(dataset['newbalanceDest']-dataset['oldbalanceDest'])-dataset['amount']\n",
    "dataset[dataset['error_balanceDest']>0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 1m+ transactions whose amount do not tally with the destination beginning and ending balances, hence \n",
    "# 'error_old_new_balanceDest' should be used as an attribute in our fraud detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Next we check for symmetry if the change in destination account is the same as the change in the original account\n",
    "if abs(dataset['newbalanceDest']-dataset['oldbalanceDest']) == abs(dataset['oldbalanceOrg'] - dataset['newbalanceOrig']):\n",
    "    dataset['asymmetry']== 1\n",
    "    \n",
    "else dataset['asymmetry']= 0\n",
    "\n",
    "dataset[dataset['isFraud']==1]['asymmetry'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a very high percentage of fraud case, 6000 out of 8000 case of fraud has the asymmetry pattern, \n",
    "# therefore we will include the asymmetry in our fraud detection model\n",
    "# although we now need to be extra careful of multicollinearity in our model if correlated attributes are present\n",
    "# we will look into removing at least one of the 4 attributes: newbalanceDest, oldbalanceDest, oldbalanceOrg, newbalanceOrig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Check on the categorical attribute 'type'\n",
    "dataset['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#to use get_dummies to transform this categorical col into 5 Cols that take values 0 and 1\n",
    "dataset=pd.get_dummies(data=dataset, columns=['type'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly in the EDA/preliminary feature selection, we drop attributes columns that are correlated to other attributes\n",
    "data = dataset.drop(['nameOrig','nameDest','newbalanceOrig','newbalanceDest','isFlaggedFraud'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Re-balance using Smote Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs= data.drop(['isFraud'], axis=1)\n",
    "\n",
    "y = data['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of 6M+ transaction, only 8000+ is fraud, the rest is not fraud. The target col \"isFraud\" is highly imbalanced towards\n",
    "# no-fraud transactions, therefore we need to balance the dataset. In this case, we use Smote Tomek to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE + Tomek links\n",
    "from imblearn.combine import SMOTETomek\n",
    "#instantiate\n",
    "sm = SMOTETomek()\n",
    "#fit, this takes a while\n",
    "X_resampled, y_resampled = sm.fit_sample(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize/standardize Xs features before applying machine learning techniques\n",
    "#scaling is especially\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#import numpy as np\n",
    "\n",
    "#scaler = StandardScaler() # instantiate\n",
    "#scaled_Xs = scaler.fit_transform(Xs) #fit\n",
    "\n",
    "#scaled_Xs = pd.DataFrame(scaled_Xs, columns=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "#clf = XGBClassifier(max_depth = 3, scale_pos_weight = weights, \\\n",
    "                n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
